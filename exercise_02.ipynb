{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02: Multi-class Classification \n",
    "In this exercise, you will train a ResNet18 model on the CIFAR10-LT from the scratch using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from imbalance_data.cifar10Imbanlance import Cifar10Imbanlance # dataloader\n",
    "from models.resnet import ResNet18 # model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "\n",
    "# Dataset\n",
    "IMBALANCE_RATIO = 0.1\n",
    "DATASET_DIR = \"/shareddata/\"\n",
    "# DATASET_DIR = \"./data\"\n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 40\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /shareddata/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:15<00:00, 10909650.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /shareddata/cifar-10-python.tar.gz to /shareddata/\n",
      "Files already downloaded and verified\n",
      "airplane: 0 samples\n",
      "automobile: 1 samples\n",
      "bird: 2 samples\n",
      "cat: 3 samples\n",
      "deer: 4 samples\n",
      "dog: 5 samples\n",
      "frog: 6 samples\n",
      "horse: 7 samples\n",
      "ship: 8 samples\n",
      "truck: 9 samples\n"
     ]
    }
   ],
   "source": [
    "imbanlance_rate = IMBALANCE_RATIO\n",
    "root = DATASET_DIR\n",
    "\n",
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "\n",
    "trainset = Cifar10Imbanlance(imbanlance_rate, transform=transform_cifar10_train, train=True, file_path=root)\n",
    "testset = Cifar10Imbanlance(imbanlance_rate, transform=transform_cifar10_test, train=False, file_path=root)\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "class_counts = {}\n",
    "for train_data, train_label in train_dataloader:\n",
    "\n",
    "    labels_list = train_label.tolist()\n",
    "    counts = torch.bincount(torch.tensor(labels_list))\n",
    "    \n",
    "    for label, count in enumerate(counts):\n",
    "        if label in class_counts:\n",
    "            class_counts[label] += count\n",
    "        else:\n",
    "            class_counts[label] = count\n",
    "\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i, count in enumerate(class_counts):\n",
    "    print(f\"{class_names[i]}: {int(count)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(num_classes=NUM_CLASS)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Take the image as the input and generate the output using the pre-defined ResNet18.\n",
    "2. Calculate the loss between the output and the corresponding label using *nn.CrossEntropyLoss()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one training batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to train.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################### Write your answer here ##################\n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    \"\"\"\n",
    "    Perform one testing batch iteration.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The machine learning model to evaluate.\n",
    "        image (torch.Tensor): Batch of input data (images).\n",
    "        target (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Model output (predictions) for the batch.\n",
    "        torch.Tensor: Loss value calculated for the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40 Train Loss: 0.0171 Acc: 0.3299\n",
      "Begin test......\n",
      "Test Loss: 0.0169 Acc: 0.2465\n",
      "Epoch: 2/40 Train Loss: 0.0125 Acc: 0.4288\n",
      "Begin test......\n",
      "Test Loss: 0.0157 Acc: 0.2824\n",
      "Epoch: 3/40 Train Loss: 0.0116 Acc: 0.4711\n",
      "Begin test......\n",
      "Test Loss: 0.0157 Acc: 0.2983\n",
      "Epoch: 4/40 Train Loss: 0.0110 Acc: 0.4909\n",
      "Begin test......\n",
      "Test Loss: 0.0140 Acc: 0.3412\n",
      "Epoch: 5/40 Train Loss: 0.0105 Acc: 0.5178\n",
      "Begin test......\n",
      "Test Loss: 0.0139 Acc: 0.3849\n",
      "Epoch: 6/40 Train Loss: 0.0097 Acc: 0.5537\n",
      "Begin test......\n",
      "Test Loss: 0.0127 Acc: 0.4297\n",
      "Epoch: 7/40 Train Loss: 0.0094 Acc: 0.5706\n",
      "Begin test......\n",
      "Test Loss: 0.0127 Acc: 0.4244\n",
      "Epoch: 8/40 Train Loss: 0.0091 Acc: 0.5855\n",
      "Begin test......\n",
      "Test Loss: 0.0114 Acc: 0.4794\n",
      "Epoch: 9/40 Train Loss: 0.0088 Acc: 0.6032\n",
      "Begin test......\n",
      "Test Loss: 0.0129 Acc: 0.4329\n",
      "Epoch: 10/40 Train Loss: 0.0085 Acc: 0.6157\n",
      "Begin test......\n",
      "Test Loss: 0.0120 Acc: 0.4715\n",
      "Epoch: 11/40 Train Loss: 0.0079 Acc: 0.6426\n",
      "Begin test......\n",
      "Test Loss: 0.0107 Acc: 0.5184\n",
      "Epoch: 12/40 Train Loss: 0.0075 Acc: 0.6616\n",
      "Begin test......\n",
      "Test Loss: 0.0105 Acc: 0.5357\n",
      "Epoch: 13/40 Train Loss: 0.0073 Acc: 0.6665\n",
      "Begin test......\n",
      "Test Loss: 0.0107 Acc: 0.5378\n",
      "Epoch: 14/40 Train Loss: 0.0071 Acc: 0.6761\n",
      "Begin test......\n",
      "Test Loss: 0.0099 Acc: 0.5660\n",
      "Epoch: 15/40 Train Loss: 0.0069 Acc: 0.6857\n",
      "Begin test......\n",
      "Test Loss: 0.0103 Acc: 0.5632\n",
      "Epoch: 16/40 Train Loss: 0.0064 Acc: 0.7089\n",
      "Begin test......\n",
      "Test Loss: 0.0091 Acc: 0.6129\n",
      "Epoch: 17/40 Train Loss: 0.0062 Acc: 0.7232\n",
      "Begin test......\n",
      "Test Loss: 0.0092 Acc: 0.6045\n",
      "Epoch: 18/40 Train Loss: 0.0060 Acc: 0.7276\n",
      "Begin test......\n",
      "Test Loss: 0.0090 Acc: 0.6232\n",
      "Epoch: 19/40 Train Loss: 0.0059 Acc: 0.7314\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.6399\n",
      "Epoch: 20/40 Train Loss: 0.0058 Acc: 0.7400\n",
      "Begin test......\n",
      "Test Loss: 0.0083 Acc: 0.6473\n",
      "Epoch: 21/40 Train Loss: 0.0054 Acc: 0.7568\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.6453\n",
      "Epoch: 22/40 Train Loss: 0.0053 Acc: 0.7639\n",
      "Begin test......\n",
      "Test Loss: 0.0082 Acc: 0.6559\n",
      "Epoch: 23/40 Train Loss: 0.0052 Acc: 0.7639\n",
      "Begin test......\n",
      "Test Loss: 0.0085 Acc: 0.6490\n",
      "Epoch: 24/40 Train Loss: 0.0051 Acc: 0.7685\n",
      "Begin test......\n",
      "Test Loss: 0.0086 Acc: 0.6505\n",
      "Epoch: 25/40 Train Loss: 0.0050 Acc: 0.7798\n",
      "Begin test......\n",
      "Test Loss: 0.0082 Acc: 0.6620\n",
      "Epoch: 26/40 Train Loss: 0.0047 Acc: 0.7863\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.6653\n",
      "Epoch: 27/40 Train Loss: 0.0047 Acc: 0.7903\n",
      "Begin test......\n",
      "Test Loss: 0.0082 Acc: 0.6682\n",
      "Epoch: 28/40 Train Loss: 0.0045 Acc: 0.7953\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.6709\n",
      "Epoch: 29/40 Train Loss: 0.0045 Acc: 0.7970\n",
      "Begin test......\n",
      "Test Loss: 0.0086 Acc: 0.6604\n",
      "Epoch: 30/40 Train Loss: 0.0044 Acc: 0.7972\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.6794\n",
      "Epoch: 31/40 Train Loss: 0.0042 Acc: 0.8115\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.6760\n",
      "Epoch: 32/40 Train Loss: 0.0042 Acc: 0.8125\n",
      "Begin test......\n",
      "Test Loss: 0.0080 Acc: 0.6804\n",
      "Epoch: 33/40 Train Loss: 0.0041 Acc: 0.8172\n",
      "Begin test......\n",
      "Test Loss: 0.0079 Acc: 0.6827\n",
      "Epoch: 34/40 Train Loss: 0.0041 Acc: 0.8131\n",
      "Begin test......\n",
      "Test Loss: 0.0079 Acc: 0.6848\n",
      "Epoch: 35/40 Train Loss: 0.0041 Acc: 0.8181\n",
      "Begin test......\n",
      "Test Loss: 0.0081 Acc: 0.6808\n",
      "Epoch: 36/40 Train Loss: 0.0040 Acc: 0.8232\n",
      "Begin test......\n",
      "Test Loss: 0.0079 Acc: 0.6870\n",
      "Epoch: 37/40 Train Loss: 0.0039 Acc: 0.8244\n",
      "Begin test......\n",
      "Test Loss: 0.0078 Acc: 0.6916\n",
      "Epoch: 38/40 Train Loss: 0.0039 Acc: 0.8279\n",
      "Begin test......\n",
      "Test Loss: 0.0078 Acc: 0.6915\n",
      "Epoch: 39/40 Train Loss: 0.0038 Acc: 0.8248\n",
      "Begin test......\n",
      "Test Loss: 0.0077 Acc: 0.6934\n",
      "Epoch: 40/40 Train Loss: 0.0038 Acc: 0.8278\n",
      "Begin test......\n",
      "Test Loss: 0.0078 Acc: 0.6923\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(trainset)\n",
    "    epoch_acc = running_cls_corrects.double() / len(trainset)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        val_loss = val_loss / len(testset)\n",
    "        val_acc = val_corrects.double() / len(testset)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Plotting Loss and Accuracy\n",
    "---\n",
    "The task is to create a function named ``plot_loss_and_accuracy`` that generates a visualization showing the training and testing loss as well as training and testing accuracy over different epochs during the training of a machine learning model.\n",
    "\n",
    "**To do**: \n",
    "1. Plot the training and testing loss curves on the left subplot.\n",
    "2. Plot the training and testing accuracy curves on the right subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_loss_and_accuracy(training_loss, training_acc, testing_loss, testing_acc):\n",
    "    \"\"\"\n",
    "    Plot training and testing loss, as well as training and testing accuracy.\n",
    "\n",
    "    Args:\n",
    "        training_loss (list or array): Training loss values over epochs.\n",
    "        training_acc (list or array): Training accuracy values over epochs.\n",
    "        testing_loss (list or array): Testing loss values over epochs.\n",
    "        testing_acc (list or array): Testing accuracy values over epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "     # Plot the training and testing loss curves in the left subplot\n",
    "    plt.subplot(1, 2, 1)  # loss subplot\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "    \n",
    "    plt.title(\"Loss over Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot the training and testing accuracy curves in the right subplot\n",
    "    plt.subplot(1, 2, 2)  # accuracy subplot\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "\n",
    "    plt.title(\"Accuracy over Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_and_accuracy(training_loss, training_acc, testing_loss, testing_acc)\n",
    "# print(training_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Instance inference and visualization\n",
    "---\n",
    "The task is to create a function named ``instance_inference`` that visualizes an image along with model predictions and class probabilities. Note that this function assumes that you have a pre-trained model and you are passing the model's output tensor as outputs. The function then extracts predictions and probabilities from this output tensor.\n",
    "**To do**: \n",
    "1. Reverse the normalization process to restore the image to its original scale and range for further plot.\n",
    "2. Calculate the prediction and the probabilities for each class.\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_inference(inputs, outputs, class_names, title=None):\n",
    "    \"\"\"\n",
    "    Display image for Tensor with model outputs and class probabilities.\n",
    "    Args:\n",
    "        inputs (CxHxW Tensor): Input image tensor.\n",
    "        outputs (Tensor): Model's output tensor.\n",
    "        class_names (list): List of class names.\n",
    "        title (str, optional): Title for the image. Default is None.\n",
    "    \"\"\"\n",
    "    images = inputs.cpu().numpy().transpose((1, 2, 0))\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "    \n",
    "    images = np.clip(images, 0, 1)\n",
    "    plt.imshow(images)\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "    ##################### Write your answer here ##################\n",
    "   \n",
    "   \n",
    "    ###############################################################\n",
    "\n",
    "\n",
    "    predicted_class = class_names[predicted.item()]\n",
    "    predicted_probability = probabilities[predicted].item()\n",
    "\n",
    "    plt.text(17, 30, f'Predicted Class: {predicted_class}\\nProbability: {predicted_probability:.2f}', \n",
    "             color='white', backgroundcolor='black', fontsize=8)\n",
    "    plt.show()\n",
    "\n",
    "    # Print probabilities for each class\n",
    "    print('Print probabilities for each class:')\n",
    "    for i in range(len(class_names)):\n",
    "        print(f'{class_names[i]}: {probabilities[i].item():.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(test_dataloader))\n",
    "inputs = inputs.to(device)\n",
    "inputs = inputs[3:4]\n",
    "\n",
    "outputs = model(inputs)\n",
    "\n",
    "instance_inference(inputs[0].cpu(), outputs, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calibration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
